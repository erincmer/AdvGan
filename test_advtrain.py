import os
import numpy as np

from tensorflow.contrib.legacy_seq2seq import embedding_rnn_decoder
from tensorflow.contrib.legacy_seq2seq import rnn_decoder
from tensorflow.contrib.legacy_seq2seq.python.ops import seq2seq
from tensorflow.contrib.rnn.python.ops import rnn_cell
import tensorflow as tf

from keras.utils.np_utils import to_categorical
from keras.layers import Embedding
from keras.layers import Dense, Input, Flatten
from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional
from keras.models import Model
from keras import backend as K
from keras.engine.topology import Layer, InputSpec

import readFBTask1Seq2Seq
from Generator import Generator
from Disc1 import DiscSentence
from Baseline import Baseline


MAX_SEQUENCE_LENGTH = 200
embedding_matrix,hist_train,hist_val,reply_train,reply_val,reply_in_train,reply_in_val,word_index = readFBTask1Seq2Seq.create_con(True,MAX_SEQUENCE_LENGTH)

EMB_DIM = len(word_index) + 1 # embedding dimension
HIDDEN_DIM = 250 # hidden state dimension of lstm cell
SEQ_LENGTH = 200 # sequence length
REP_SEQ_LENGTH = 20
START_TOKEN = 0
END_TOKEN = word_index.get("eos")
HIST_END_TOKEN = word_index.get("eoh")
PRE_EPOCH_NUM = 120 # supervise (maximum likelihood estimation) epochs
SEED = 88
BATCH_SIZE = 64
MC_NUM = 1


generator = Generator(len(word_index) + 1, BATCH_SIZE, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH,REP_SEQ_LENGTH,START_TOKEN,END_TOKEN,HIST_END_TOKEN)
discriminator = DiscSentence(SEQ_LENGTH, word_index, embedding_matrix)
baseline = Baseline(SEQ_LENGTH,REP_SEQ_LENGTH,BATCH_SIZE, word_index, embedding_matrix)


config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
generator.assign_emb(sess,embedding_matrix)

idxTrain = np.arange(len(hist_train))
loss_t = 0


def concat_hist_reply( histories, replies, word_index):
    disc_inp = np.full((BATCH_SIZE, MAX_SEQUENCE_LENGTH), word_index['eos'])
    counter = 0
    for h, r in zip(histories, replies):

        i = 0
        while i != word_index['eoh']:
            disc_inp[counter, i] = h[i]
            i = i + 1

        disc_inp[counter, i] = word_index['eoh']

        disc_inp[counter, i + 1:i + 21] = r
        counter = counter + 1

    return disc_inp


for ep in range(1):
    np.random.shuffle(idxTrain)

    for j in range(0, hist_train.shape[0] // BATCH_SIZE):

        X = hist_train[idxTrain[j*BATCH_SIZE:(j+1)*BATCH_SIZE],:]
        Y = reply_train[idxTrain[j*BATCH_SIZE:(j+1)*BATCH_SIZE],:]

        _,sentence = generator.generate(sess, X, Y)

        rewards = generator.MC_reward(sess, X, sentence, MC_NUM, discriminator,word_index)

        print(np.array(rewards).shape)





        # TODO insert new sentence into history
        # start_insert = tf.reduce_sum(tf.to_int32(tf.not_equal(X, word_index['eoh'])), 1).eval(session=sess)
        # start_insert = start_insert.reshape(BATCH_SIZE)
        history_update = np.copy(X)
        #history_update = np.insert(history_update, start_insert,complete_sentence, axis=1)
        # history_update = concat_hist_reply(history_update, sentence, word_index)
        b = baseline.get_baseline(history_update,sentence,word_index)

        print(b.shape)
        print(b[0,0])
        #rewards = np.tile(np.arange(REP_SEQ_LENGTH)/(1.0 * REP_SEQ_LENGTH), (64,1))
        #baseline = np.tile(np.arange(REP_SEQ_LENGTH)/(1.0 * REP_SEQ_LENGTH), (64,1))

        print("Y.shape", Y.shape)
        print("baseline.shape", b.shape)
        print("rewards.shape", rewards.shape)
        # TODO: b has a bad shape
        generator.advtrain_step(sess, X, Y, sentence, rewards, b)

        baseline.train(history_update,sentence,rewards,word_index)






















def count_nonzero(X):
    return (X != 0).sum(1)

def init_matrix(shape,embedding_matrix = None):

    if embedding_matrix is not None:
        emd = tf.constant(embedding_matrix,name="W")
        return emd
    else:
        return tf.random_normal(shape, stddev=0.1)

print('Traing and validation set number of positive and negative reviews')

seq_length = 200
rep_seq_length = 20
BATCH_SIZE = 64

vocab_size = len(word_index) + 1
emb_dim = len(word_index) + 1

memory_dim = 400



labels = [tf.placeholder(tf.int32, shape=(None,),
                        name="labels%i" % t)
          for t in range(rep_seq_length)]

weights = [tf.ones_like(labels_t, dtype=tf.float32)
           for labels_t in labels]
teacher_force = tf.placeholder(tf.bool)

seq_len = tf.placeholder(tf.int32, shape=(None,))
enc_inp = tf.placeholder(tf.int32, shape=[BATCH_SIZE, seq_length])  # sequence of tokens generated by generator
# g_embeddings = tf.Variable(init_matrix(embedding_matrix,[vocab_size, emb_dim]))
g_embeddings = tf.Variable(tf.constant(0.0, shape=[vocab_size, emb_dim]),
                trainable=False, name="W")

embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, emb_dim])
embedding_init = g_embeddings.assign(embedding_placeholder)


# Decoder input: prepend some "GO" token and drop the final
# token of the encoder input
# dec_inp = ([tf.zeros_like(labels[0], dtype=np.int32, name="GO")]
#            + labels[:-1])
dec_inp = [tf.placeholder(tf.int32, shape=(None,),
                        name="labels%i" % t)
          for t in range(rep_seq_length)]
# dec_inp = tf.placeholder(tf.int32, shape=[BATCH_SIZE, rep_seq_length])
# Initial memory value for recurrence.
prev_mem = tf.zeros((BATCH_SIZE, memory_dim))
with tf.device("/cpu:0"):

    processed_x = tf.transpose(tf.nn.embedding_lookup(g_embeddings, enc_inp), perm=[0, 1, 2])
    processed_y = tf.transpose(dec_inp, perm=[1, 0])
enc_inp0 = [tf.placeholder(tf.int32, shape=(None,),
                          name="inp%i" % t)
           for t in range(seq_length)]
with tf.variable_scope("encoder", reuse=None) as scope:

        enc_cell = tf.contrib.rnn.GRUCell(memory_dim)
        # enc_cell = tf.contrib.rnn.EmbeddingWrapper(
        #     enc_cell, embedding_classes=vocab_size,
        #     embedding_size=emb_dim)
        #
        #
        # basic_cell = tf.contrib.rnn.DropoutWrapper(
        #     encoder_cell,
        #     output_keep_prob=self.keep_prob)
        # _, encoder_state = tf.contrib.rnn.static_rnn(enc_cell, enc_inp,prev_mem)
        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(enc_cell,processed_x,seq_len,prev_mem)
        # _, encoder_state = tf.contrib.rnn.static_rnn(enc_cell,enc_inp0, dtype=tf.float32)

with tf.variable_scope("decoder", reuse=None) as scope:

        cell = tf.contrib.rnn.GRUCell(memory_dim)
        # dec_cell = tf.contrib.rnn.EmbeddingWrapper(
        #     cell, embedding_classes=vocab_size,
        #     embedding_size=embedding_dim)
        dec_cell = tf.contrib.rnn.OutputProjectionWrapper(cell, vocab_size)


        dec_outputs, dec_memory,emb_inps,dec_in = embedding_rnn_decoder(dec_inp,
                                                        encoder_state,
                                                        dec_cell,
                                                        vocab_size,
                                                        emb_dim,
                                                        seq_len,
                                                        update_embedding_for_previous=False,
                                                        feed_previous=False)

        soft_dec= tf.nn.softmax(dec_outputs)
learning_rate = 0.0005

optimizer = tf.train.AdamOptimizer(learning_rate)
loss = tf.contrib.legacy_seq2seq.sequence_loss(dec_outputs, labels, weights,vocab_size)
train_op = optimizer.minimize(loss)
train_list = []

print("trainable variables//////////////////////////")
for v in tf.trainable_variables():
    print(v.name)
    if "embeddings:0" not in v.name and "embedding:0" not in v.name:
        train_list.append(v)
        # print(v.name,v.get_shape().as_list())

input("wait")
train_op = optimizer.minimize(loss,var_list = train_list)

sess.run(tf.global_variables_initializer())

savepathTask = 'Models/AdvGanTask1/'  # best is saved here
saver_all = tf.train.Saver()

if not os.path.exists(savepathTask):
    os.makedirs(savepathTask)

# saver_all.restore(sess, tf.train.latest_checkpoint(savepathTask))

var_2 = [v for v in tf.global_variables() if v.name == "decoder/embedding_rnn_decoder/embedding:0"][0]

op2 =  var_2.assign(embedding_matrix)

sess.run(embedding_init, feed_dict={embedding_placeholder: embedding_matrix})
sess.run(op2)


e2 = var_2.eval(session=sess)


print(" after emb 2 = " , e2[0:3,0:3])


e2 = var_2.eval(session=sess)


idxTrain = np.arange(len(hist_train))
loss_t = 0
for ep in range(10000):
    np.random.shuffle(idxTrain)

    for j in range(0, hist_train.shape[0] // BATCH_SIZE):

        if True:
            X = hist_train[idxTrain[j*BATCH_SIZE:(j+1)*BATCH_SIZE],:]

            Y = reply_train[idxTrain[j*BATCH_SIZE:(j+1)*BATCH_SIZE],:]
            Y_in = reply_in_train[idxTrain[j * BATCH_SIZE:(j + 1) * BATCH_SIZE], :]

            Y = np.array(Y).T
            Y_in = np.array(Y_in).T
            feed_dict = {enc_inp: X }
            feed_dict.update({dec_inp[t]: Y_in[t] for t in range(rep_seq_length)})
            feed_dict.update({labels[t]: Y[t] for t in range(rep_seq_length)})

            feed_dict.update({seq_len: count_nonzero(X)})

            feed_dict.update({teacher_force: True })
            _, loss_t = sess.run([train_op, loss], feed_dict)
            print(loss_t)
        if False and j %100 ==0:
            if j  == 0:
                saver_all.save(sess, savepathTask + 'my-model-sentence-sen-1024')
                print("saved")

            X = hist_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]

            s = np.random.randint(0, X.shape[0])
            s_q =  np.random.randint(4, size = BATCH_SIZE)
            s_q = s_q.T
            Y = reply_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]
            Y_in = np.array(list(reply_in_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]))
            print(Y_in[0:3, :])
            Y_in[:,4:] = 0
            print(Y_in[0:3, :])
            X = np.array(X).T
            Y = np.array(Y).T
            Y_in = np.array(Y_in).T

            feed_dict = {enc_inp[t]: X[t] for t in range(seq_length)}
            feed_dict.update({dec_inp: Y_in for t in range(rep_seq_length)})
            feed_dict.update({labels[t]: Y[t] for t in range(rep_seq_length)})
            feed_dict.update({teacher_force: False})
            feed_dict.update({seq_len: s_q})
            dec_outputs_batch,emb_inps_batch,dec_in_batch = sess.run([dec_outputs, emb_inps,dec_in], feed_dict)
            d2 = np.array(dec_in_batch)

            d1 = np.array(emb_inps_batch)
            print("dec inp  = ")
            print(np.argmax(d2[:, 0, :],axis = 1))
            print(np.argmax(d2[:, 1, :], axis=1))
            print(np.argmax(d2[:, 2, :], axis=1))
            # print(d2.shape)
            # print(d2[:, 0])
            print("emb_inp = ")
            print(np.argmax(d1[:, 0, :],axis = 1))
            print(np.argmax(d1[:, 1, :], axis=1))
            print(np.argmax(d1[:, 2, :], axis=1))

            Y = Y.T
            # print(Y.shape)

            print("real output 1")
            output = ""
            for x in Y[s]:
                if x!=0:
                    output = output + " "+str(x)
            print(output,loss_t)
            output = ""
            print("predicted 1")
            dec_out = [logits_t.argmax(axis=1) for logits_t in dec_outputs_batch]
            dec_out = np.array(dec_out).T
            # print(dec_out.shape)
            for ss in dec_out[:3]:
                for x in ss:
                    if x!=0:
                        output = output + " "+str(x)
                print(output,loss_t)
            print("////////////////////////////////////////////")
            input("wait")
            X = hist_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]


            Y = reply_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]
            Y_in = reply_in_train[j * BATCH_SIZE:(j + 1) * BATCH_SIZE, :]
            X = np.array(X).T
            Y = np.array(Y).T
            Y_in = np.array(Y_in).T
            print("dec inp  before = ")
            print(Y_in[:, 0])

            feed_dict = {enc_inp[t]: X[t] for t in range(seq_length)}
            feed_dict.update({dec_inp[t]: Y_in[t] for t in range(rep_seq_length)})
            feed_dict.update({labels[t]: Y[t] for t in range(rep_seq_length)})
            feed_dict.update({teacher_force: False})
            feed_dict.update({seq_len: s_q})
            dec_outputs_batch,emb_inps_batch = sess.run([soft_dec,emb_inps], feed_dict)
            d1 = np.array(emb_inps_batch)

            print("emb_inp = ")
            print(np.argmax(d1[:, 0, :],axis = 1))

            Y = Y.T
            # print(Y.shape)


            print("real output 2")
            output = ""
            for x in Y[s]:
                if x != 0:
                    output = output + " " + str(x)
            print(output, loss_t)
            output = ""
            print("predicted 2")
            dec_out = [logits_t.argmax(axis=1) for logits_t in dec_outputs_batch]
            dec_out = np.array(dec_out).T
            # print(dec_out.shape)
            for x in dec_out[s]:
                if x != 0:
                    output = output + " " + str(x)
            print(output, loss_t)
            print("////////////////////////////////////////////")
            input("wait")